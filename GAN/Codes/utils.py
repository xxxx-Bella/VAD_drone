#import tensorflow as tf
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()

import numpy as np
from collections import OrderedDict
import os
import glob
import cv2


rng = np.random.RandomState(2017)


def np_load_frame(filename, resize_height, resize_width):
    """
    Load image path and convert it to numpy.ndarray. Notes that the color channels are BGR and the color space
    is normalized from [0, 255] to [-1, 1].

    :param filename: the full path of image
    :param resize_height: resized height
    :param resize_width: resized width
    :return: numpy.ndarray
    """
    image_decoded = cv2.imread(filename)  # 读取图片文件(图片路径, 读取图片的形式)
    image_resized = cv2.resize(image_decoded, (resize_width, resize_height))  # 只改变 image 的 width 和 height
    image_resized = image_resized.astype(dtype=np.float32)
    image_resized = (image_resized / 127.5) - 1.0  # normalization -> [-1, 1]
    return image_resized


class DataLoader(object):
    def __init__(self, video_folder, resize_height=256, resize_width=256):
        self.dir = video_folder
        self.videos = OrderedDict()  # 有序字典
        self._resize_height = resize_height
        self._resize_width = resize_width
        self.setup()

    def __call__(self, batch_size, time_steps=4, num_pred=1):  # 实现__call__()的对象，相当于重载了()，可以实现调用功能
        video_info_list = list(self.videos.values())  # videos.values()有 path, frame, length
        num_videos = len(video_info_list)  # 视频的总数
        print('\n')
        print('##########################')
        print('num_videos =', num_videos, '\n')

        clip_length = time_steps + num_pred  # 需要用到连续 t 帧，预测 1 帧  # 4+1=5
        print('clip_length =', clip_length, '\n')
        resize_height, resize_width = self._resize_height, self._resize_width

        def video_clip_generator():  # 生成视频片段的generator(使用了yield的函数被称为生成器)
            v_id = -1
            while True:
                v_id = (v_id + 1) % num_videos

                video_info = video_info_list[v_id]  # 对于其中一个视频
                if video_info['length'] > clip_length:
                    # print('v_id =', v_id)
                    # print('video_info[length] =', video_info['length'], '<= clip_length')
                    start = rng.randint(0, video_info['length'] - clip_length)  # 除了要用的t帧和要预测的帧数，随机从此前的一个位置开始
                    video_clip = []
                    for frame_id in range(start, start + clip_length):
                        video_clip.append(np_load_frame(video_info['frame'][frame_id], resize_height, resize_width)) # np_load_frame: size转化为256x256并归一化 后的帧/image(array)
                        # video_info['frame'][frame_id] 即 该视频的其中一个帧，如：000.jpg
                    video_clip = np.concatenate(video_clip, axis=2)  # video_clip.shape=(resize_height, resize_width, clip_length)

                    yield video_clip  # 返回一个可迭代的生成器对象，可以用for循环或者调用next()遍历生成器对象来提取结果

        # video clip paths
        dataset = tf.data.Dataset.from_generator(generator=video_clip_generator,
                                                 output_types=tf.float32,
                                                 output_shapes=[resize_height, resize_width, clip_length * 3])  # Creates a `Dataset` whose elements are generated by `generator`
        print('generator dataset, {}'.format(dataset))
        dataset = dataset.prefetch(buffer_size=1000)  # prefetch()允许在处理当前元素时准备以后的buffer_size个元素
        dataset = dataset.shuffle(buffer_size=1000).batch(batch_size)  # buffer_size影响dataset的随机性，即元素生成的顺序; batch()将数据集的连续batch_size个元素组合成批
        print('epoch dataset, {}'.format(dataset))

        return dataset  # 组合成 batch的 dataset

    def __getitem__(self, video_name):  # 获取 video_name 对应的内容
        assert video_name in self.videos.keys(), 'video = {} is not in {}!'.format(video_name, self.videos.keys())  # assert 判断一个表达式，在表达式条件为 false 的时候触发异常。在条件不满足程序运行的情况下直接返回错误，而不必等待程序运行后出现崩溃的情况
        return self.videos[video_name]

    def setup(self):
        videos = glob.glob(os.path.join(self.dir, '*'))  # os.path.join()连接两个或更多的路径名组件, 此处即 dir/*(*为通配符); glob.glob()返回所有匹配的文件路径列表 (如ped2数据集的 ..\training\frames\*，*有01,...,16共十六个视频)
        for video in sorted(videos):  # 依次操作每个视频
            video_name = video.split('/')[-1]  # 01, 02, ..., 16
            self.videos[video_name] = {}
            self.videos[video_name]['path'] = video
            self.videos[video_name]['frame'] = glob.glob(os.path.join(video, '*.jpg'))  # video路径下所有.jpg的列表 (如 ..\training\frames\01\000.jpg), 即视频的每一帧
            self.videos[video_name]['frame'].sort()
            self.videos[video_name]['length'] = len(self.videos[video_name]['frame'])  # .jpg文件的数量，即视频的帧数（图像数）

    def get_video_clips(self, video, start, end):  # 获取一个视频片段
        # assert video in self.videos, 'video = {} must in {}!'.format(video, self.videos.keys())
        # assert start >= 0, 'start = {} must >=0!'.format(start)
        # assert end <= self.videos[video]['length'], 'end = {} must <= {}'.format(video, self.videos[video]['length'])

        batch = []
        for i in range(start, end):
            image = np_load_frame(self.videos[video]['frame'][i], self._resize_height, self._resize_width)  # shape[resize_height, resize_width, clip_length]
            batch.append(image)

        return np.concatenate(batch, axis=2)  # 将获取到的每个batch的帧按第3维度(clip_length)连接


def log10(t):
    """
    Calculates the base-10 log of each element in t.

    @param t: The tensor from which to calculate the base-10 log.

    @return: A tensor with the base-10 log of each element in t.
    """

    numerator = tf.math.log(t)  # 分子
    denominator = tf.math.log(tf.constant(10, dtype=numerator.dtype))  # 分母
    return numerator / denominator


def psnr_error(gen_frames, gt_frames):
    """
    Computes the Peak Signal to Noise Ratio error between the generated images and the ground
    truth images.
    High PSNR of the t-th frame indicates that it is MORE likely to be normal.

    @param gen_frames: A tensor of shape [batch_size, height, width, 3]. The frames generated by the
                       generator model. # Generator生成的帧
    @param gt_frames: A tensor of shape [batch_size, height, width, 3]. The ground-truth frames for
                      each frame in gen_frames. # 生成帧对应的真实帧

    @return: A scalar tensor. The mean Peak Signal to Noise Ratio error over each frame in the
             batch.
    """
    shape = tf.shape(gen_frames)   # gen_frames.shape = (1, 256, 256, 12)
    num_pixels = tf.compat.v1.to_float(shape[1] * shape[2] * shape[3])  # 像素数
    gt_frames = (gt_frames + 1.0) / 2.0
    gen_frames = (gen_frames + 1.0) / 2.0
    square_diff = tf.square(gt_frames - gen_frames)

    batch_errors = 10 * log10(1 / ((1 / num_pixels) * tf.reduce_sum(square_diff, [1, 2, 3])))
    return tf.reduce_mean(batch_errors)


# D(I) and D(I^)
def diff_mask(gen_frames, gt_frames, min_value=-1, max_value=1):
    # normalize PSNR of all frames in each testing video to the range [0, 1]
    delta = max_value - min_value
    # regular score S(t)
    gen_frames = (gen_frames - min_value) / delta 
    gt_frames = (gt_frames - min_value) / delta

    gen_gray_frames = tf.image.rgb_to_grayscale(gen_frames)
    gt_gray_frames = tf.image.rgb_to_grayscale(gt_frames)

    diff = tf.abs(gen_gray_frames - gt_gray_frames)
    return diff


def load(saver, sess, ckpt_path):
    saver.restore(sess, ckpt_path)
    print("Restored model parameters from {}".format(ckpt_path))


def save(saver, sess, logdir, step):
    model_name = 'model.ckpt'
    checkpoint_path = os.path.join(logdir, model_name)
    if not os.path.exists(logdir):
        os.makedirs(logdir)
    saver.save(sess, checkpoint_path, global_step=step)
    print('The checkpoint has been created.')




